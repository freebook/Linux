<?xml version="1.0" encoding="UTF-8"?>
<section id="k3s">
	<title>K3s</title>
	<section>
		<title>安装 K3s</title>
		<para>K3S 的安装方式有多种，官方提供的 k3s-install.sh，还有第三方的 k3d 和 k3sup</para>
		<section>
			<title>Server 服务安装</title>
			<para></para>
			<screen>
			<![CDATA[
hostnamectl set-hostname master
			]]>
			</screen>
			<screen>
			<![CDATA[
curl -sfL https://get.k3s.io | sh -			
			]]>
			</screen>
			<para>国内镜像</para>
			<screen>
		<![CDATA[
curl -sfL http://rancher-mirror.cnrancher.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh -
systemctl enable k3s
		]]>
			</screen>
			<para>查看节点启动状态</para>
			<screen>
			<![CDATA[
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1
			]]>
			</screen>
			<para>查看节点 Pod 状态</para>
			<screen>
		<![CDATA[
kubectl --kubeconfig /etc/rancher/k3s/k3s.yaml get pods --all-namespaces
		]]>
			</screen>
		</section>
		<section>
			<title>Agent 代理安装</title>
			<para></para>
			<screen>
			<![CDATA[
hostnamectl set-hostname node1			
			]]>
			</screen>
			<para>查看 Master Token</para>
			<screen>
			<![CDATA[
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1

[root@master ~]# cat /var/lib/rancher/k3s/server/node-token
K1000ba39a142b3712d2ffb1459a63f6a7f58b082aeb53406dab15d8cee0f3c2ff0::server:5713047feb086388c19663f69cccc966
			]]>
			</screen>
			<para>在节点服务器安装代理</para>
			<screen>
			<![CDATA[
SERVER=172.18.200.5
TOKEN=K1000ba39a142b3712d2ffb1459a63f6a7f58b082aeb53406dab15d8cee0f3c2ff0::server:5713047feb086388c19663f69cccc966			
curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn K3S_URL=https://${SERVER}:6443 K3S_TOKEN=${TOKEN} sh -
systemctl enable k3s-agent
			]]>
			</screen>
			<para>回到 Master 查看节点</para>
			<screen>
			<![CDATA[
[root@master ~]# kubectl get node
NAME                    STATUS   ROLES                  AGE    VERSION
localhost.localdomain   Ready    control-plane,master   28m    v1.24.4+k3s1
node1                   Ready    <none>                 117s   v1.24.4+k3s1			
			]]>
			</screen>
		</section>
	</section>
	<section id="k3d">
		<title>k3d</title>
		<para>k3d is a lightweight wrapper to run k3s (Rancher Lab’s minimal
			Kubernetes distribution) in docker.</para>
		<section>
			<title>安装 k3d</title>

			<para>Mac 安装 k3d</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ brew install k3d			
			]]>
			</screen>
			<para>Linux 安装 k3d</para>
			<command>wget -q -O -
				https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
			</command>
			<screen>
			<![CDATA[
[root@netkiller ~]# wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/main/install.sh | bash
Preparing to install k3d into /usr/local/bin
k3d installed into /usr/local/bin/k3d
Run 'k3d --help' to see what you can do with it.
			]]>
			</screen>
		</section>
		<section>
			<title>创建集群</title>
			<para>创建并启动集群</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ k3d cluster create mycluster
INFO[0000] Prep: Network                                
INFO[0000] Created network 'k3d-mycluster'              
INFO[0000] Created volume 'k3d-mycluster-images'        
INFO[0000] Starting new tools node...                   
INFO[0001] Creating node 'k3d-mycluster-server-0'       
INFO[0006] Pulling image 'docker.io/rancher/k3d-tools:5.2.2' 
INFO[0006] Pulling image 'docker.io/rancher/k3s:v1.21.7-k3s1' 
INFO[0016] Starting Node 'k3d-mycluster-tools'          
INFO[0036] Creating LoadBalancer 'k3d-mycluster-serverlb' 
INFO[0041] Pulling image 'docker.io/rancher/k3d-proxy:5.2.2' 
INFO[0057] Using the k3d-tools node to gather environment information 
INFO[0058] Starting cluster 'mycluster'                 
INFO[0058] Starting servers...                          
INFO[0059] Starting Node 'k3d-mycluster-server-0'       
INFO[0078] All agents already running.                  
INFO[0078] Starting helpers...                          
INFO[0079] Starting Node 'k3d-mycluster-serverlb'       
INFO[0087] Injecting '192.168.65.2 host.k3d.internal' into /etc/hosts of all nodes... 
INFO[0087] Injecting records for host.k3d.internal and for 2 network members into CoreDNS configmap... 
INFO[0088] Cluster 'mycluster' created successfully!    
INFO[0088] You can now use it like this:                
kubectl cluster-info			
			]]>
			</screen>
			<para>映射80端口</para>
			<screen>
			<![CDATA[
k3d cluster create mycluster --api-port 127.0.0.1:6445 --servers 3 --agents 2 --port '80:80@loadbalancer'
			]]>
			</screen>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ k3d cluster create mycluster --api-port 127.0.0.1:6445 --servers 3 --agents 2 --port '80:80@loadbalancer'
INFO[0000] portmapping '80:80' targets the loadbalancer: defaulting to [servers:*:proxy agents:*:proxy] 
INFO[0000] Prep: Network                                
INFO[0000] Created network 'k3d-mycluster'              
INFO[0000] Created volume 'k3d-mycluster-images'        
INFO[0000] Creating initializing server node            
INFO[0000] Creating node 'k3d-mycluster-server-0'       
INFO[0000] Starting new tools node...                   
INFO[0001] Starting Node 'k3d-mycluster-tools'          
INFO[0002] Creating node 'k3d-mycluster-server-1'       
INFO[0003] Creating node 'k3d-mycluster-server-2'       
INFO[0004] Creating node 'k3d-mycluster-agent-0'        
INFO[0005] Creating node 'k3d-mycluster-agent-1'        
INFO[0005] Creating LoadBalancer 'k3d-mycluster-serverlb' 
INFO[0005] Using the k3d-tools node to gather environment information 
INFO[0007] Starting cluster 'mycluster'                 
INFO[0007] Starting the initializing server...          
INFO[0007] Starting Node 'k3d-mycluster-server-0'       
INFO[0012] Starting servers...                          
INFO[0013] Starting Node 'k3d-mycluster-server-1'
INFO[0045] Starting Node 'k3d-mycluster-server-2'       
INFO[0069] Starting agents...                           
INFO[0070] Starting Node 'k3d-mycluster-agent-1'        
INFO[0070] Starting Node 'k3d-mycluster-agent-0'        
INFO[0081] Starting helpers...                          
INFO[0081] Starting Node 'k3d-mycluster-serverlb'       
INFO[0089] Injecting '192.168.65.2 host.k3d.internal' into /etc/hosts of all nodes... 
INFO[0089] Injecting records for host.k3d.internal and for 6 network members into CoreDNS configmap... 
INFO[0090] Cluster 'mycluster' created successfully!    
INFO[0091] You can now use it like this:                
kubectl cluster-info			
			]]>
			</screen>
			<para>除了使用命令，还可以使用 yaml 配置文件创建集群</para>
			<programlisting>
			<![CDATA[
apiVersion: k3d.io/v1alpha2
kind: Simple
name: mycluster
servers: 1
agents: 2
kubeAPI:
  hostPort: "6443" # same as `--api-port '6443'`
ports:
  - port: 8080:80  # same as `--port '8080:80@loadbalancer'`
    nodeFilters:
      - loadbalancer
  - port: 8443:443 # same as `--port '8443:443@loadbalancer'`
    nodeFilters:
      - loadbalancer			
			]]>
			</programlisting>
			<para></para>
			<screen>
			<![CDATA[
$ k3d cluster create --config /path/to/mycluster.yaml			
			]]>
			</screen>
		</section>
		<section>
			<title>查看信息</title>
			<para></para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ k3d cluster list
NAME        SERVERS   AGENTS   LOADBALANCER
mycluster   3/3       2/2      true			
			]]>
			</screen>
			<para>查看集群信息</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ kubectl cluster-info
Kubernetes control plane is running at https://0.0.0.0:60268
CoreDNS is running at https://0.0.0.0:60268/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Metrics-server is running at https://0.0.0.0:60268/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
Neo-iMac:~ neo$ 			
			]]>
			</screen>
			<para>查看节点</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ kubectl get nodes
NAME                     STATUS   ROLES                  AGE     VERSION
k3d-mycluster-server-0   Ready    control-plane,master   2m10s   v1.21.7+k3s1			
			]]>
			</screen>
		</section>
		<section>
			<title>删除集群</title>
			<para>删除集群</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ k3d cluster delete mycluster
INFO[0000] Deleting cluster 'mycluster'                 
INFO[0002] Deleting cluster network 'k3d-mycluster'     
INFO[0003] Deleting image volume 'k3d-mycluster-images' 
INFO[0003] Removing cluster details from default kubeconfig... 
INFO[0003] Removing standalone kubeconfig file (if there is one)... 
INFO[0003] Successfully deleted cluster mycluster!   			
			]]>
			</screen>
		</section>
		<section>
			<title>演示</title>
			<section>
				<title>部署 nginx</title>
				<screen>
				<![CDATA[
Neo-iMac:~ neo$ kubectl create deployment nginx --image=nginx:alpine
deployment.apps/nginx created
Neo-iMac:~ neo$ kubectl create service clusterip nginx --tcp=80:80
service/nginx created
Neo-iMac:~ neo$ cat <<EOF | kubectl apply -f -
> apiVersion: networking.k8s.io/v1
> kind: Ingress
> metadata:
>   name: nginx
>   annotations:
>     ingress.kubernetes.io/ssl-redirect: "false"
> spec:
>   rules:
>   - http:
>       paths:
>       - path: /
>         pathType: Prefix
>         backend:
>           service:
>             name: nginx
>             port:
>               number: 80
> EOF
ingress.networking.k8s.io/nginx created				
				]]>
				</screen>
				<para>查看 ingress 状态</para>
				<screen>
				<![CDATA[
Netkiller-iMac:~ neo$ kubectl get ingress  -o wide
NAME    CLASS    HOSTS   ADDRESS                                                  PORTS   AGE
nginx   <none>   *       172.19.0.2,172.19.0.3,172.19.0.4,172.19.0.5,172.19.0.6   80      54m				
				]]>
				</screen>
				<para>使用浏览器或者CURL命令访问 http://localhost</para>
				<screen>
				<![CDATA[
Neo-iMac:~ neo$ curl http://localhost
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>				
				]]>
				</screen>
			</section>
		</section>
		<section>
			<title>配置文件</title>
			<section>
				<title>导出集群配置文件</title>
				<screen>
				<![CDATA[
Netkiller-iMac:~ neo$ k3d kubeconfig write mycluster
/Users/neo/.k3d/kubeconfig-mycluster.yaml
Netkiller-iMac:~ neo$ cat /Users/neo/.k3d/kubeconfig-mycluster.yaml
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJkakNDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdGMyVnkKZG1WeUxXTmhRREUyTkRFME16WTVNelV3SGhjTk1qSXdNVEEyTURJME1qRTFXaGNOTXpJd01UQTBNREkwTWpFMQpXakFqTVNFd0h3WURWUVFEREJock0zTXRjMlZ5ZG1WeUxXTmhRREUyTkRFME16WTVNelV3V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFUQVZKN01XdVY3dzA5dGZybUswbDAybkxOcjFiaGpXM1hIZEgrQUtCdWEKREFBZ3UrNHF4dVdyNHBkbGpraVNrL3ZZMEJjVWJMZ1RkemJnSEY4UnA1OVpvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVUZ2UXVRTVBjeStrbTFla2pqaUtUCmRoZ1c4TjB3Q2dZSUtvWkl6ajBFQXdJRFJ3QXdSQUlnVGMvZDBHWjN5aWRuZ2dXamZGWnowc0R6V3diVXkzV0IKVmZYamZ1Tis3UjRDSUJ4ZmttSUs1Z1NTL0RNUjltc0VxYUsxZVNGTEl2bHZuNXhaeE53RDJoUlgKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=
    server: https://127.0.0.1:6445
  name: k3d-mycluster
contexts:
- context:
    cluster: k3d-mycluster
    user: admin@k3d-mycluster
  name: k3d-mycluster
current-context: k3d-mycluster
kind: Config
preferences: {}
users:
- name: admin@k3d-mycluster
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJrVENDQVRlZ0F3SUJBZ0lJVnR3SGsxWDlUam93Q2dZSUtvWkl6ajBFQXdJd0l6RWhNQjhHQTFVRUF3d1kKYXpOekxXTnNhV1Z1ZEMxallVQXhOalF4TkRNMk9UTTFNQjRYRFRJeU1ERXdOakF5TkRJeE5Wb1hEVEl6TURFdwpOakF5TkRJMU0xb3dNREVYTUJVR0ExVUVDaE1PYzNsemRHVnRPbTFoYzNSbGNuTXhGVEFUQmdOVkJBTVRESE41CmMzUmxiVHBoWkcxcGJqQlpNQk1HQnlxR1NNNDlBZ0VHQ0NxR1NNNDlBd0VIQTBJQUJCcFNScmNGMW9VQUFCRW4Kb2hZM1haWmpoMUhkNks0eEtXVUpsc3A2blR0UzNFbDJJQjZrUmZIcGNwaDdjQ3NaUnFvV2RsT1MxdlFtNGM3VgplNVZ6aEY2alNEQkdNQTRHQTFVZER3RUIvd1FFQXdJRm9EQVRCZ05WSFNVRUREQUtCZ2dyQmdFRkJRY0RBakFmCkJnTlZIU01FR0RBV2dCVFhrTVpDYnJXVTNKQmxIb0t2Z0F4MDF6TUJUVEFLQmdncWhrak9QUVFEQWdOSUFEQkYKQWlFQTFIQ0M1OUlaS3FieVQ2MExSS2pvcWNWMFJiK3BWZ1FLdU1aR3YxZXFvOGdDSUZFMjB6OTg1ZStnR3dGYQppK3FkenFYQTVKU2FrV05naVE0TUZLcExpVDI3Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0KLS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUJlRENDQVIyZ0F3SUJBZ0lCQURBS0JnZ3Foa2pPUFFRREFqQWpNU0V3SHdZRFZRUUREQmhyTTNNdFkyeHAKWlc1MExXTmhRREUyTkRFME16WTVNelV3SGhjTk1qSXdNVEEyTURJME1qRTFXaGNOTXpJd01UQTBNREkwTWpFMQpXakFqTVNFd0h3WURWUVFEREJock0zTXRZMnhwWlc1MExXTmhRREUyTkRFME16WTVNelV3V1RBVEJnY3Foa2pPClBRSUJCZ2dxaGtqT1BRTUJCd05DQUFTd0c2dk9tay8vL01jNlUwU3BLZm9ERFM1NDNkQnZSdzVZUnNlZmpmWm0KT01BQUNRbkViYS9QY0FGc2ZIUlBWWU9HczRnWTQ3TVlDbzF3L2swV3had3lvMEl3UURBT0JnTlZIUThCQWY4RQpCQU1DQXFRd0R3WURWUjBUQVFIL0JBVXdBd0VCL3pBZEJnTlZIUTRFRmdRVTE1REdRbTYxbE55UVpSNkNyNEFNCmROY3pBVTB3Q2dZSUtvWkl6ajBFQXdJRFNRQXdSZ0loQUtQcjE3T0lDNk94a1hBYnpxUGl2R0QwZkptVjFmTnIKVFNzc2IvMktWMjh4QWlFQTFEUVlHU2F0V3R6Y2tFdk1JNnYzeTcyQ2hwdDZWMHZUdWNEWWJsOWxRVFU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    client-key-data: LS0tLS1CRUdJTiBFQyBQUklWQVRFIEtFWS0tLS0tCk1IY0NBUUVFSUxjTWt1aW9mTHo1Z1lUZGVrWmlsOEhTZVMzSXVONHVHUGU2VXFxRWJkN0dvQW9HQ0NxR1NNNDkKQXdFSG9VUURRZ0FFR2xKR3R3WFdoUUFBRVNlaUZqZGRsbU9IVWQzb3JqRXBaUW1XeW5xZE8xTGNTWFlnSHFSRgo4ZWx5bUh0d0t4bEdxaFoyVTVMVzlDYmh6dFY3bFhPRVhnPT0KLS0tLS1FTkQgRUMgUFJJVkFURSBLRVktLS0tLQo=				
				]]>
				</screen>
			</section>
		</section>
		<section>
			<title>镜像管理</title>
			<para>导入本地镜像</para>
			<screen>
			<![CDATA[
Netkiller-iMac:~ neo$ docker image ls | grep netkiller
netkiller                                                     openjdk8       52e22fa28d43   3 weeks ago    552MB			
			]]>
			</screen>
			<para>将本地 netkiller:openjdk8 镜像导入到 mycluster 中</para>
			<screen>
			<![CDATA[
Netkiller-iMac:~ neo$ k3d image import netkiller:openjdk8 -c mycluster
INFO[0000] Importing image(s) into cluster 'mycluster'  
INFO[0000] Loading 1 image(s) from runtime into nodes... 
INFO[0051] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-0'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-2'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-agent-1'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-server-1'... 
INFO[0050] Importing images '[netkiller:openjdk8]' into node 'k3d-mycluster-agent-0'... 
INFO[0355] Successfully imported image(s)               
INFO[0355] Successfully imported 1 image(s) into 1 cluster(s) 			
			]]>
			</screen>
		</section>

	</section>
	<section>
		<title>管理 k3d 集群</title>
		<screen>
		<![CDATA[
[root@netkiller k3d]# k3d cluster start mycluster		
		]]>
		</screen>
		<section>
			<title>配置 api-port 端口</title>
			<screen>
			<![CDATA[
k3d cluster create netkiller --api-port 6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer'
			]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
[root@netkiller ~]# cat .kube/config | grep server
    server: https://0.0.0.0:6445
    
[root@netkiller ~]# ss -lnt | grep 6445
LISTEN 0      1024         0.0.0.0:6445       0.0.0.0:*  			
			]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
[root@netkiller ~]# firewall-cmd --add-service=http --permanent
success
[root@netkiller ~]# firewall-cmd --add-service=https --permanent
success
[root@netkiller ~]# firewall-cmd --zone=public --add-service=kube-api --permanent  
success			
			]]>
			</screen>
		</section>
		<section>
			<title></title>
			<para></para>
			<screen>
			<![CDATA[
k3d cluster create netkiller --api-port 172.16.0.1:6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer' --k3s-arg "--no-deploy=traefik@server:*"
			]]>
			</screen>
			export http_proxy="socks://127.0.0.1:1080"
			export
			https_proxy="socks://127.0.0.1:1080"
		</section>
		<section>
			<title>kubectl 管理指定集群</title>
			<screen>
			<![CDATA[
export KUBECONFIG="$(k3d kubeconfig write netkiller)"			
			]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
[root@netkiller ~]# kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://172.18.200.10:6445
  name: k3d-netkiller
contexts:
- context:
    cluster: k3d-netkiller
    user: admin@k3d-netkiller
  name: k3d-netkiller
current-context: k3d-netkiller
kind: Config
preferences: {}
users:
- name: admin@k3d-netkiller
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED			
			]]>
			</screen>
		</section>
	</section>
	<section>
		<title>容器镜像库</title>
		<screen>
		<![CDATA[
neo@Netkiller-iMac ~> vim ~/.k3d/registries.yaml
mirrors:
  "registry.netkiller.cn":
    endpoint:
      - http://registry.netkiller.cn
		]]>
		</screen>
		<para></para>
		<screen>
		<![CDATA[
neo@Netkiller-iMac ~> k3d cluster create mycluster --api-port 6443 --servers 1 --agents 1 --port '80:80@loadbalancer' --port '443:443@loadbalancer' --registry-config ~/.k3d/registries.yaml		
		]]>
		</screen>
	</section>
	<section id="traefik">
		<title>traefik 配置</title>
		<section>
			<title>增加 Redis 6379 端口</title>

			<screen>
		<![CDATA[
neo@Netkiller-iMac ~> kubectl edit -n kube-system deployment traefik
deployment.apps/traefik edited		
		]]>
			</screen>
			<para></para>
			<screen>
		<![CDATA[
    spec:
      containers:
      - args:
        - --global.checknewversion
        - --global.sendanonymoususage
        - --entrypoints.traefik.address=:9000/tcp
        - --entrypoints.web.address=:8000/tcp
        - --entrypoints.websecure.address=:8443/tcp
        - --entrypoints.redis.address=:6379/tcp
        - --entrypoints.mysql.address=:3306/tcp
        - --entrypoints.mongo.address=:27017/tcp
        - --api.dashboard=true
        - --ping=true
        - --providers.kubernetescrd
        - --providers.kubernetesingress
        - --providers.kubernetesingress.ingressendpoint.publishedservice=kube-system/traefik
        - --entrypoints.websecure.http.tls=true
        image: rancher/library-traefik:2.4.8
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /ping
            port: 9000
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 2
        name: traefik
        ports:
        - containerPort: 9000
          name: traefik
          protocol: TCP
        - containerPort: 8000
          name: web
          protocol: TCP
        - containerPort: 8443
          name: websecure
          protocol: TCP
        - containerPort: 6379
          name: redis
          protocol: TCP
        - containerPort: 3306
          name: mysql
          protocol: TCP
        - containerPort: 27017
          name: mongo
          protocol: TCP		
		]]>
			</screen>
			<para>args 处加入</para>
			<screen>
		<![CDATA[
- --entrypoints.redis.address=:6379/tcp		
		]]>
			</screen>
			<para>ports 处加入</para>
			<screen>
		<![CDATA[
		- containerPort: 6379
          name: redis
          protocol: TCP
		]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
[root@netkiller k3d]# k3d cluster edit mycluster --port-add '6379:6379@loadbalancer'			      
			]]>
			</screen>
			<programlisting>
			<![CDATA[
[root@netkiller k3d]# cat redis.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
spec:
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:latest
        ports:
        - containerPort: 6379
          protocol: TCP
---
apiVersion: v1
kind: Service
metadata:
  name: redis
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
--- 
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRouteTCP
metadata:
  name: redis
spec:
  entryPoints:
    - redis
  routes:
  - match: HostSNI(`*`)
    services:
    - name: redis
      port: 6379			
			]]>
			</programlisting>
			<screen>
			<![CDATA[
[root@netkiller k3d]# kubectl apply -f redis.yaml
deployment.apps/redis created
service/redis created
ingressroutetcp.traefik.containo.us/redis created

[root@netkiller k3d]# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
redis-5c9986b94b-gsctv   1/1     Running   0          6m49s
[root@netkiller k3d]# kubectl exec redis-5c9986b94b-gsctv -it  -- redis-cli
127.0.0.1:6379> set nickname netkiller
OK
127.0.0.1:6379> get nickname
"netkiller"
127.0.0.1:6379>		
127.0.0.1:6379> exit
			]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
[root@netkiller k3d]# dnf install redis
[root@netkiller k3d]# redis-cli -h 127.0.0.1
127.0.0.1:6379> get nickname
			]]>
			</screen>
		</section>

	</section>
	<section id="k3d.ingress-nginx">
		<title>ingress-nginx</title>
		<section>
			<title>卸载 traefik</title>
			<para>我们希望使用 nginx ingress，所以需要讲 traefik 卸载</para>
			<screen>
			<![CDATA[
kubectl -n kube-system delete helmcharts.helm.cattle.io traefik
helm uninstall traefik-crd --namespace kube-system			
			]]>
			</screen>
		</section>
		<section>
			<title>安装 ingress-nginx</title>
			<para>ingress-nginx:
				https://kubernetes.github.io/ingress-nginx/deploy/</para>
			<screen>
			<![CDATA[
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml
			]]>
			</screen>
			<para>修改镜像库地址，否则无法下载</para>
			<screen>
			<![CDATA[
wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.3.0/deploy/static/provider/cloud/deploy.yaml
vim deploy.yaml
:%s:registry.k8s.io/ingress-nginx/:registry.cn-hangzhou.aliyuncs.com/google_containers/:g  			
:%s:registry.cn-hangzhou.aliyuncs.com/google_containers/controller:registry.cn-hangzhou.aliyuncs.com/google_containers/nginx-ingress-controller:g 
			]]>
			</screen>
			<para>svclb-ingress-nginx-controller 启动不起来</para>
			<screen>
			<![CDATA[
neo@MacBook-Pro-Neo-3 ~ [1]> kubectl logs -n kube-system svclb-ingress-nginx-controller-8b62cc7d-qbqtv
Defaulted container "lb-tcp-80" out of: lb-tcp-80, lb-tcp-443
+ trap exit TERM INT
+ echo 10.43.36.160
+ grep -Eq :
+ cat /proc/sys/net/ipv4/ip_forward
+ '[' 1 '!=' 1 ]
+ iptables -t nat -I PREROUTING '!' -s 10.43.36.160/32 -p TCP --dport 80 -j DNAT --to 10.43.36.160:80
iptables v1.8.4 (legacy): can't initialize iptables table `nat': Table does not exist (do you need to insmod?)
Perhaps iptables or your kernel needs to be upgraded.			
			]]>
			</screen>
			<para>解决方法</para>
			<screen>
			<![CDATA[
root@netkiller ~ # modprobe ip_tables

root@netkiller ~# lsmod|grep iptable
iptable_nat            16384  2
ip_tables              28672  1 iptable_nat
nf_nat                 53248  4 xt_nat,nft_chain_nat,iptable_nat,xt_MASQUERADE

root@netkiller ~# kubectl get pods --all-namespaces
NAMESPACE       NAME                                            READY   STATUS      RESTARTS         AGE
ingress-nginx   ingress-nginx-admission-create-nqv2f            0/1     Completed   0                6m9s
ingress-nginx   ingress-nginx-admission-patch-m9hcf             0/1     Completed   1                6m9s
kube-system     metrics-server-7cd5fcb6b7-8wrqx                 1/1     Running     3 (6m30s ago)    82m
ingress-nginx   ingress-nginx-controller-75d55647d-nstch        1/1     Running     0                6m9s
kube-system     coredns-d76bd69b-rgvwj                          1/1     Running     3 (6m21s ago)    82m
kube-system     local-path-provisioner-6c79684f77-psmgs         1/1     Running     3 (6m21s ago)    82m
kube-system     svclb-ingress-nginx-controller-8b62cc7d-5lb8d   2/2     Running     12 (3m17s ago)   6m9s
kube-system     svclb-ingress-nginx-controller-8b62cc7d-qbqtv   2/2     Running     12 (3m20s ago)   6m9s
			]]>
			</screen>
		</section>
		<section>
			<title>验证安装是否正确</title>
			<para>部署 Nginx Web 服务器，用来检查 ingress</para>
			<screen>
			<![CDATA[
Neo-iMac:~ neo$ kubectl create deployment nginx --image=nginx:alpine
deployment.apps/nginx created

Neo-iMac:~ neo$ kubectl create service clusterip nginx --tcp=80:80
service/nginx created			
			]]>
			</screen>
			<para></para>
			<screen>
			<![CDATA[
cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nginx
  annotations:
    kubernetes.io/ingress.class: nginx
    ingress.kubernetes.io/ssl-redirect: "false"
spec:
  rules:
  - http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: nginx
            port:
              number: 80
EOF			
			]]>
			</screen>
		</section>

	</section>
	<section>
		<title>FAQ</title>
		<section>
			<title>ghcr.io 镜像下载问题</title>
			<para>创建集群始终停止在这里，这是因为 ghcr.io 被墙，无法访问。</para>
			<screen>
			<![CDATA[
INFO[0004] Pulling image 'ghcr.io/k3d-io/k3d-proxy:5.4.4' 			
			]]>
			</screen>
			<para>找一台境外VPS安装K3D并创建集群，然后讲 k3d-proxy 镜像保存为文件。</para>
			<screen>
			<![CDATA[
[docker@netkiller ~]$ docker images
REPOSITORY                 TAG            IMAGE ID       CREATED        SIZE
ghcr.io/k3d-io/k3d-proxy   5.4.4          5a963719cb39   2 weeks ago    42.4MB
ghcr.io/k3d-io/k3d-tools   5.4.4          741f01cb5093   2 weeks ago    18.7MB
			
[docker@netkiller ~]$ docker save 5a963719cb39 -o k3d-proxy.tar			
			]]>
			</screen>
			<para>复制到国内，导入镜像</para>
			<screen>
			<![CDATA[
docker load --input k3d-proxy.tar			
			]]>
			</screen>
		</section>
	</section>
</section>